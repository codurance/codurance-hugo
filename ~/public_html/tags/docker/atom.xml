<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docker on Software Craftsmanship and Agile Development</title>
    <link>http://codurance.com/tags/docker/</link>
    <description>Recent content in Docker on Software Craftsmanship and Agile Development</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <lastBuildDate>Wed, 16 Mar 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://codurance.com/tags/docker/atom/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Containers all the way through...</title>
      <link>http://codurance.com/blog/containers-all-the-way-through/</link>
      <pubDate>Wed, 16 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>http://codurance.com/blog/containers-all-the-way-through/</guid>
      <description>

&lt;p&gt;In this post I will attempt to cover fundamentals of &lt;strong&gt;Bare Metal Systems&lt;/strong&gt;, &lt;strong&gt;Virtual Systems&lt;/strong&gt; and &lt;strong&gt;Container Systems&lt;/strong&gt;. And the purpose for doing so is to learn about these systems as they stand and also the differences between them, focusing on how they execute programs in their respective environments.&lt;/p&gt;

&lt;h3 id=&#34;bare-metal-systems&#34;&gt;Bare Metal Systems&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s think of our Bare Metal Systems as desktops and laptops we use on a daily basis (or even servers in server rooms and data-centers), and we have the following components:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;the hardware (outer physical layer)&lt;/li&gt;
&lt;li&gt;the OS platform (running inside the hardware)&lt;/li&gt;
&lt;li&gt;the programs running on the OS (as processes)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Programs are stored on the hard drive in the form of executable files (a format understandable by the OS) and loaded into memory via one or more processes. Programs interact with the kernel, which forms a core part of the OS architecture and the hardware. The OS coordinate communication between hardware i.e. CPU, I/O devices, Memory, etcâ€¦ and the programs.&lt;/p&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-16-containers-all-the-way-through/bare-metal-systems.png&#34; alt=&#34;Bare Metal Systems&#34; title=&#34;Bare Metal Systems&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;p&gt;A more detailed explanation of what programs or executables are, how programs execute and where an Operating System come into play, can be found &lt;a href=&#34;http://stackoverflow.com/questions/1599434/how-does-program-execute-where-does-the-operating-systems-come-into-play&#34;&gt;on this Stackoverflow page [2]&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;virtual-systems&#34;&gt;Virtual Systems&lt;/h3&gt;

&lt;p&gt;On the other hand Virtual Systems, with the help of Virtual System controllers like, &lt;em&gt;Virtual Box&lt;/em&gt; or &lt;em&gt;VMWare&lt;/em&gt; or &lt;a href=&#34;https://en.wikipedia.org/wiki/Hypervisor&#34;&gt;&lt;em&gt;a&lt;/em&gt; &lt;em&gt;hypervisor [1]&lt;/em&gt;&lt;/a&gt; run an operating system on a bare metal system. These systems emulate bare-metal hardware as software abstraction(s) inside which we run the real OS platform. Such systems can be made up of the following layers, and also referred to as a Virtual Machines (VM):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a software abstraction of the hardware (Virtual Machine)&lt;/li&gt;
&lt;li&gt;the OS platform running inside the software abstraction (guest OS)&lt;/li&gt;
&lt;li&gt;one or more programs running in the guest OS (processes)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It&amp;rsquo;s like running a computer (abstracted as software) inside another computer. And the rest of the fundamentals from the Bare Metal System applies to this abstraction layer as well. When a process is created inside the Virtual System, then the host OS which runs the Virtual System might also be spawning one or more processes.&lt;/p&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-16-containers-all-the-way-through/virtual-systems.png&#34; alt=&#34;Virtual Systems&#34; title=&#34;Virtual Systems&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;h3 id=&#34;container-systems&#34;&gt;Container Systems&lt;/h3&gt;

&lt;p&gt;Now looking at Container Systems we can say the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;they run on top of OS platforms running inside Bare Metal Systems or Virtual Systems&lt;/li&gt;
&lt;li&gt;containers which allow isolating processes and sharing the kernel between each other (such isolation from other processes and resources are possible in some OSes like say Linux, due to OS kernel features like &lt;a href=&#34;https://en.wikipedia.org/wiki/Cgroups&#34;&gt;&lt;em&gt;cgroups&lt;/em&gt;&lt;/a&gt;[3] and &lt;a href=&#34;http://man7.org/linux/man-pages/man7/namespaces.7.html&#34;&gt;&lt;em&gt;namespaces&lt;/em&gt;&lt;/a&gt;)[4]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A container creates an OS like environment, inside which one or more programs can be executed. Each of these executions could result in a one or more processes on the host OS. Container Systems are composed of these layers:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;hardware (accessible via kernel features)&lt;/li&gt;
&lt;li&gt;the OS platform (shared kernel)&lt;/li&gt;
&lt;li&gt;one or more programs running inside the container (as processes)&lt;/li&gt;
&lt;/ul&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-16-containers-all-the-way-through/container-systems.png&#34; alt=&#34;Container Systems&#34; title=&#34;Container Systems&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;

&lt;p&gt;Looking at these enclosures or rounded rectangles within each other, we can already see how it is containers all the way through.&lt;/p&gt;

&lt;div class=&#34;row blog-boxes&#34;&gt;
   &lt;div class=&#34;blog-box homepage-blog-thumb col-md-4&#34;&gt; 
    
&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-16-containers-all-the-way-through/bare-metal-systems.png&#34; alt=&#34;Bare Metal Systems&#34; title=&#34;Bare Metal Systems&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;
 
   &lt;/div&gt;
   &lt;div class=&#34;blog-box homepage-blog-thumb col-md-4&#34;&gt;
    
&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-16-containers-all-the-way-through/virtual-systems.png&#34; alt=&#34;Virtual Systems&#34; title=&#34;Virtual Systems&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;

   &lt;/div&gt;
   &lt;div class=&#34;blog-box homepage-blog-thumb col-md-4&#34;&gt;
    
&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-16-containers-all-the-way-through/container-systems.png&#34; alt=&#34;Container Systems&#34; title=&#34;Container Systems&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;
 
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;There is an increasing number of distinctions between &lt;strong&gt;Bare Metal Systems&lt;/strong&gt;, &lt;strong&gt;Virtual Systems&lt;/strong&gt; and &lt;strong&gt;Container Systems&lt;/strong&gt;. While Virtual Systems encapsulate the Operating System inside a thick hardware virtualisation, Container Systems do something similar but with a much thinner virtualisation layer.&lt;/p&gt;

&lt;p&gt;There are a number of pros and cons between these systems when we look at them individually, i.e. portability, performance, resource consumption, time to recreate such systems, maintenance, et al.&lt;/p&gt;

&lt;h3 id=&#34;word-of-thanks-and-stay-in-touch&#34;&gt;Word of thanks and stay in touch&lt;/h3&gt;

&lt;p&gt;Thank you for your time, feel free to send your queries and comments to &lt;a href=&#34;http://twitter.com/theNeomatrix369&#34;&gt;theNeomatrix369&lt;/a&gt;. Big thanks to my colleagues, our DevOps craftsman &lt;a href=&#34;https://twitter.com/robertfirek&#34;&gt;Robert Firek&lt;/a&gt; and craftsman &lt;a href=&#34;https://twitter.com/dhatanian&#34;&gt;David Hatanian&lt;/a&gt; from &lt;a href=&#34;http://codurance.com/aboutus/ourcompany/&#34;&gt;Codurance&lt;/a&gt; for giving invaluable feedback on my post and steering me in the right direction.&lt;/p&gt;

&lt;h3 id=&#34;resources&#34;&gt;Resources&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;[1] &lt;a href=&#34;https://en.wikipedia.org/wiki/Hypervisor&#34;&gt;Wikipedia page for Hypervisor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[2] &lt;a href=&#34;http://stackoverflow.com/questions/1599434/how-does-program-execute-where-does-the-operating-systems-come-into-play&#34;&gt;Stackoverflow page for &amp;ldquo;How does a program execute? Where does the operating systems come into play ?&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[3] &lt;a href=&#34;https://en.wikipedia.org/wiki/Cgroups&#34;&gt;Wikipedia page on cgroups&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[4] &lt;a href=&#34;http://man7.org/linux/man-pages/man7/namespaces.7.html&#34;&gt;Linux man page on namespaces&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Docker meets Continuous Deployment</title>
      <link>http://codurance.com/blog/docker-meets-continuous-deployment/</link>
      <pubDate>Tue, 01 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>http://codurance.com/blog/docker-meets-continuous-deployment/</guid>
      <description>

&lt;p&gt;About one year ago I had my first contact with Docker. This new kid on the block promised to relieve our poor computers from installation of all tools, languages, dependencies and operating systems. Isolated run environments emerged on developers&amp;rsquo; computers.&lt;/p&gt;

&lt;p&gt;While my ops teammates chose a more conservative approach, I started to use Docker with great joy. Despite many people describing Docker as a tool written by developers for development, our industry found new ways of using images and containers. Images of our applications and services became deployment units for tools like Kubernetes, Docker Swarm or Marathon.&lt;/p&gt;

&lt;p&gt;But how are these images created?&lt;/p&gt;

&lt;h2 id=&#34;setting-the-scene&#34;&gt;Setting The Scene&lt;/h2&gt;

&lt;p&gt;From a developer&amp;rsquo;s perspective, any application is manifested by its code, but there is still a long way to go before this code finds its way to a production environment. I want to show you how this process can be easier with &lt;strong&gt;Docker&lt;/strong&gt; and a &lt;strong&gt;Continuous Deployment&lt;/strong&gt; pipeline.&lt;/p&gt;

&lt;p&gt;First of all we need a small application with a HTTP API that we can call after it&amp;rsquo;s deployed. Let&amp;rsquo;s assume that we are using &lt;strong&gt;Gradle&lt;/strong&gt; to build the application and &lt;strong&gt;TeamCity&lt;/strong&gt; as a Continuous Integration server.&lt;/p&gt;

&lt;p&gt;We need to have &lt;strong&gt;Docker&lt;/strong&gt; installed on each &lt;strong&gt;TeamCity&lt;/strong&gt; build agent. We will also use this machine to run our application. In a real project we wouldn&amp;rsquo;t install &lt;strong&gt;TeamCity&lt;/strong&gt; agents on all machines. Instead we should use tools like Kubernetes that will take care of the application distribution.&lt;/p&gt;

&lt;h2 id=&#34;build&#34;&gt;Build&lt;/h2&gt;

&lt;p&gt;As a first step in our Continuous Deployment pipeline, before we even think about Docker images, we need to build our application. In this step we will download the source code, run all &lt;strong&gt;tests&lt;/strong&gt; and produce an &lt;strong&gt;artifact&lt;/strong&gt; containing all elements required to start and run our application.&lt;/p&gt;

&lt;p&gt;This build configuration is not very different to a step in a Continuous Deployment pipeline without &lt;strong&gt;Docker&lt;/strong&gt;. Alongside common parameters we have to define &lt;strong&gt;artifacts&lt;/strong&gt;, which will be generated after each build run. We are going to use them as a base for next steps in the pipeline.&lt;/p&gt;

&lt;p&gt;In &lt;strong&gt;TeamCity&lt;/strong&gt; we define &lt;strong&gt;artifacts&lt;/strong&gt; by defining paths to files from the working directory (which is created for each run of a configuration). The working directory is a combination of the files downloaded from a version control system and the files generated during the execution of build steps. The working directory elements are defined in the version control settings and build steps.&lt;/p&gt;

&lt;p&gt;We need two artifacts. The first one is &lt;code&gt;Dockerfile&lt;/code&gt;. We already prepared this file in our source code and it will be stored in the &lt;code&gt;docker&lt;/code&gt; directory.
The next file is a &lt;strong&gt;&lt;em&gt;tar&lt;/em&gt;&lt;/strong&gt; file which will be generated by our &lt;strong&gt;Gradle&lt;/strong&gt; build. It contains a script that executes our code and all required libraries.&lt;/p&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-01-docker-meets-continuous-deployment/build_config.png&#34; alt=&#34;Build Configuration&#34; title=&#34;Build Configuration&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;p&gt;Now we are ready to instruct our build configuration how to download our source code. We use GitHub as our code repository, so we just have to choose &lt;em&gt;Git&lt;/em&gt; as the type of our &lt;strong&gt;Version Control System&lt;/strong&gt; and provide the URL to our application.&lt;/p&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-01-docker-meets-continuous-deployment/build_vcs.png&#34; alt=&#34;Version Control Configuration&#34; title=&#34;Version Control Configuration&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;p&gt;With the source code in our working directory we can describe what to do with it. As I mentioned before we run all the &lt;strong&gt;tests&lt;/strong&gt; and generate an &lt;strong&gt;artifact&lt;/strong&gt; containing the start script and libraries.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TeamCity&lt;/strong&gt; has predefined runners for different build tools. In this case we are going to use the &lt;strong&gt;Gradle&lt;/strong&gt; runner to &lt;strong&gt;test&lt;/strong&gt; and &lt;strong&gt;build&lt;/strong&gt;.&lt;/p&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-01-docker-meets-continuous-deployment/build_step.png&#34; alt=&#34;Gradle Step&#34; title=&#34;Gradle Step&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;p&gt;Now we can run our build and as a result we should see our &lt;strong&gt;artifacts&lt;/strong&gt; in the &lt;em&gt;&amp;ldquo;Artifacts&amp;rdquo;&lt;/em&gt; tab.&lt;/p&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-01-docker-meets-continuous-deployment/build_result.png&#34; alt=&#34;Build Result&#34; title=&#34;Build Result&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;h2 id=&#34;release&#34;&gt;Release&lt;/h2&gt;

&lt;p&gt;Our code is no longer needed. We have all we need to build the docker image. Now we have to create our image and &lt;strong&gt;release&lt;/strong&gt; it with the right version. To simplify our example we are going to use the current build number to define an image version.
Next we will generate a file with this version. This file gives us the possibility to pass information about the version to the next steps.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s take a closer look at the &lt;code&gt;Dockerfile&lt;/code&gt;. We copy the content of &lt;code&gt;simple_application.tar&lt;/code&gt; (which contains all required libraries and scripts) to the image, by using the &lt;code&gt;ADD&lt;/code&gt; command. This command will automatically &lt;em&gt;untar&lt;/em&gt; all files inside the image. Next we expose the port of our HTTP API and we define how to launch our application by adding an &lt;code&gt;ENTRYPOINT&lt;/code&gt; command.&lt;/p&gt;

&lt;p&gt;For example our &lt;code&gt;Dockerfile&lt;/code&gt; can look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;FROM java:8

ADD simple_application.tar .

EXPOSE 4567

ENTRYPOINT [&amp;quot;/simple_application/bin/simple_application&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Defining the build configuration is very simple. In general settings we define a new artifact: &lt;code&gt;image.version&lt;/code&gt;. The content of this file will be generated in the one of the build steps.&lt;/p&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-01-docker-meets-continuous-deployment/release_config.png&#34; alt=&#34;Release Configuration&#34; title=&#34;Release Configuration&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;p&gt;Without the &lt;strong&gt;artifact&lt;/strong&gt; we won&amp;rsquo;t be able to build any image. We have to tell our build how to find the &lt;strong&gt;artifacts&lt;/strong&gt; generated during the &lt;strong&gt;Build&lt;/strong&gt; phase. We can do that by defining an &lt;strong&gt;Artifact Dependency&lt;/strong&gt; in &lt;strong&gt;TeamCity&lt;/strong&gt;. We just have to choose a build configuration, define the &lt;strong&gt;artifacts&lt;/strong&gt; from that build and &lt;strong&gt;TeamCity&lt;/strong&gt; will add them to the working directory.&lt;/p&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-01-docker-meets-continuous-deployment/release_artifacts.png&#34; alt=&#34;Release Artifact Dependency&#34; title=&#34;Release Artifact Dependency&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;p&gt;And finally we have to trigger this build automatically after all &lt;strong&gt;tests&lt;/strong&gt; run by the previous step pass. By introducing &lt;strong&gt;Finish Build Trigger&lt;/strong&gt; we can start this build just after &lt;strong&gt;TeamCity&lt;/strong&gt; successfully finishes building the application.&lt;/p&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-01-docker-meets-continuous-deployment/release_trigger.png&#34; alt=&#34;Release Trigger&#34; title=&#34;Release Trigger&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;p&gt;Now we are ready for a release. Three build steps must be introduced: &lt;strong&gt;Build Image&lt;/strong&gt;, &lt;strong&gt;Push Image&lt;/strong&gt; and &lt;strong&gt;Save Version&lt;/strong&gt;.
This time we will use a different runner type: &lt;strong&gt;Command Line&lt;/strong&gt;. We can execute a shell script on a build agent. Because we have already installed &lt;strong&gt;Docker&lt;/strong&gt; on our build agent we can use the &lt;code&gt;docker&lt;/code&gt; command in our shell script.&lt;/p&gt;

&lt;h3 id=&#34;build-image&#34;&gt;Build Image&lt;/h3&gt;

&lt;p&gt;To build the image we need to execute the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker build --tag registry.private/simple_application:%build.number% .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Docker&amp;rsquo;s &lt;code&gt;build&lt;/code&gt; command will take our &lt;code&gt;Dockerfile&lt;/code&gt; and build the image tagged as &lt;code&gt;registry.private/simple_application&lt;/code&gt; and the version &lt;code&gt;%build.number%&lt;/code&gt;.
The variable &lt;code&gt;%build.number%&lt;/code&gt; is a built-in &lt;strong&gt;TeamCity&lt;/strong&gt; variable containing the current build number.&lt;/p&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-01-docker-meets-continuous-deployment/release_step_1.png&#34; alt=&#34;Release Build Image Step&#34; title=&#34;Release Build Image Step&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;h3 id=&#34;push-image&#34;&gt;Push Image&lt;/h3&gt;

&lt;p&gt;The image created in the previous step exists only on the agent machine. To make the image available to others we need to store it in a repository. We can use &lt;strong&gt;Docker Hub&lt;/strong&gt;, but in our example we use a private repository available under the address &lt;code&gt;repository.private&lt;/code&gt;. We can execute the following command to push the image to the repository.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker push registry.private/simple_application:%build.number%
&lt;/code&gt;&lt;/pre&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-01-docker-meets-continuous-deployment/release_step_2.png&#34; alt=&#34;Release Push Image to Repository Step&#34; title=&#34;Release Push Image to Repository Step&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;h3 id=&#34;save-version&#34;&gt;Save Version&lt;/h3&gt;

&lt;p&gt;The image is safely stored in the repository, but we need to do one more step: save the version of our image. Once again we run a shell script to generate an &lt;code&gt;image.version&lt;/code&gt; file:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo %build.number% &amp;gt; image.version
&lt;/code&gt;&lt;/pre&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-01-docker-meets-continuous-deployment/release_step_3.png&#34; alt=&#34;Release Save Version Step&#34; title=&#34;Release Save Version Step&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;h2 id=&#34;deploy&#34;&gt;Deploy&lt;/h2&gt;

&lt;p&gt;In the previous step we created an image which we can use now to deploy our application. We are going to create another build configuration: &lt;strong&gt;Deploy&lt;/strong&gt;. This build will run a Docker container on the &lt;strong&gt;TeamCity&lt;/strong&gt; agent based on the image from the &lt;strong&gt;Release&lt;/strong&gt; phase.&lt;/p&gt;

&lt;p&gt;Our build configuration must contain three elements. The first one is a trigger. Again, we use the &lt;strong&gt;Finish Build Trigger&lt;/strong&gt; with a dependency to the &lt;strong&gt;Release&lt;/strong&gt; build configuration.&lt;/p&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-01-docker-meets-continuous-deployment/deploy_trigger.png&#34; alt=&#34;Deploy Trigger&#34; title=&#34;Deploy Trigger&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;p&gt;The second element is a version string of our image. We can obtain this information from the &lt;strong&gt;artifact&lt;/strong&gt; created by the &lt;strong&gt;Release&lt;/strong&gt; build.&lt;/p&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-01-docker-meets-continuous-deployment/deploy_artifact.png&#34; alt=&#34;Deploy Artifact&#34; title=&#34;Deploy Artifact&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;p&gt;The last step is a little bit more complicated. Before we deploy the new version of the application the deployment script need to check if the container with the previous version is already deployed on the machine. If we have such a container we need to stop and remove it.
Next we read the current version from the &lt;strong&gt;artifact&lt;/strong&gt; and create the new container based this version.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;if [ -n &amp;quot;$(docker ps --filter label=simple_application -q)&amp;quot; ]; then 
   docker stop simple_application
   docker rm simple_application
fi;

version_to_deploy=$(cat image.version)
docker run -d -p 80:4567 \
           --name simple_application \
           --label simple_application \
           registry.private/simple_application:${version_to_deploy}
&lt;/code&gt;&lt;/pre&gt;


&lt;img src=&#34;http://codurance.com/assets/img/custom/blog/2016-03-01-docker-meets-continuous-deployment/deploy_step.png&#34; alt=&#34;Deploy Step&#34; title=&#34;Deploy Step&#34; class=&#34;img img-responsive style-screengrab&#34;/&gt;


&lt;p&gt;The Continuous Deployment pipeline is ready. Now every change in the master branch of our repository will build, test, release and deploy our application.&lt;/p&gt;

&lt;h2 id=&#34;it-s-done&#34;&gt;It&amp;rsquo;s done.&lt;/h2&gt;

&lt;p&gt;The continuous deployment pipeline described in this post is of course simplified. Between our &lt;strong&gt;Release&lt;/strong&gt; and &lt;strong&gt;Deploy&lt;/strong&gt; steps we would like to do some
additional tests on a production-like environment or introduce &lt;a href=&#34;http://codurance.com/services/training/devops-training/&#34;&gt;zero downtime deployments&lt;/a&gt;, but our approach to any deployment should remain unchanged.&lt;/p&gt;

&lt;p&gt;Use the &lt;strong&gt;Docker&lt;/strong&gt; image. You can ensure a consistent execution environment for your application on every stage of the Continuous Deployment. Now you decide how the code is executed and you cannot blame admins anymore for installing a wrong version of Java or Ruby.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Making Sense of Docker Volumes</title>
      <link>http://codurance.com/blog/making-sense-of-docker-volumes/</link>
      <pubDate>Wed, 15 Apr 2015 10:00:00 +0000</pubDate>
      
      <guid>http://codurance.com/blog/making-sense-of-docker-volumes/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://www.docker.com&#34;&gt;Docker&lt;/a&gt; is a platform that allows users to build, ship, and run distributed applications. Applications are stored inside &lt;strong&gt;docker containers&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;A docker container uses a &lt;strong&gt;Union File System&lt;/strong&gt; which consists of read-only layers and a read / write layer on top.&lt;/p&gt;

&lt;p&gt;Whilst the container is running, it is possible to write information to disk, however, when the container is removed that information does not persist.&lt;/p&gt;

&lt;p&gt;In order to persist information it is necessary to &lt;strong&gt;mount a volume&lt;/strong&gt;. A volume operates outside of the Union File System - any information written to the read/write layer will be copied to the volume.&lt;/p&gt;

&lt;p&gt;The great thing about volumes is that they decouple the life of the data being stored in them from the life of the container that created them. The volume continues to be accessible on the host machine even if the container is removed or no longer running.&lt;/p&gt;

&lt;h2 id=&#34;mounting-a-volume&#34;&gt;Mounting a Volume&lt;/h2&gt;

&lt;p&gt;Volumes can be mounted to container at run time &amp;hellip;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d -P --name javaContainer -v /myVol bin/echo &amp;quot;Doing java stuff&amp;quot; &amp;gt; /myVol/java_activity.txt

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip; or from within the docker file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;FROM java
RUN mkdir /myvol
RUN echo &amp;quot;Doing java stuff&amp;quot; &amp;gt; /myvol/java_activity.txt
VOLUME /myvol
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But what if you have multiple instances of the application that need to access the same volume? You need to make the most of the sharability that Docker provides.&lt;/p&gt;

&lt;h2 id=&#34;the-data-container-pattern&#34;&gt;The Data Container Pattern&lt;/h2&gt;

&lt;p&gt;Rather than mounting a volume to your application&amp;rsquo;s container, the Data Container Pattern closely follows the single responsibility principle.&lt;/p&gt;

&lt;p&gt;It involves setting up a volume in a separate &lt;strong&gt;data container&lt;/strong&gt;. Your application container then points to the data container to read and write information (using the &lt;strong&gt;volume-from&lt;/strong&gt; command). This is a common practice when working with databases.&lt;/p&gt;

&lt;h2 id=&#34;the-lifecycle-of-a-data-container&#34;&gt;The Lifecycle of a Data Container&lt;/h2&gt;

&lt;p&gt;The data container only runs whilst it is needed and is does next to nothing in terms of work. The application container mounts the volume contained inside the data container, once this is done the data container shuts down.&lt;/p&gt;

&lt;h2 id=&#34;preventing-problems&#34;&gt;Preventing Problems&lt;/h2&gt;

&lt;p&gt;When creating a data container (e.g for storing information from a database application) it&amp;rsquo;s wise to use the same base image in both your application container and data container. This will prevent any file permission issues as the data container will seed the application container with the correct file permissions and brings about greater efficiency as you are reusing the image.&lt;/p&gt;

&lt;h2 id=&#34;further-reading&#34;&gt;Further reading&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/userguide/dockervolumes/&#34;&gt;Docker Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://container42.com/2013/12/16/persistent-volumes-with-docker-container-as-volume-pattern/&#34;&gt;Persistent volumes with Docker - Data-only container pattern&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://container-solutions.com/2014/12/understanding-volumes-docker/&#34;&gt;Understanding volumes in Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://container42.com/2014/11/03/docker-indepth-volumes/&#34;&gt;Docker Indepth: Volumes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;thanks&#34;&gt;Thanks&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Many thanks to Rob Taylor and Mash Badar for proof-reading this article&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>